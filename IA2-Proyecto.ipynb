{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/jessica/opt/anaconda3/envs/IA2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jessica/opt/anaconda3/envs/IA2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jessica/opt/anaconda3/envs/IA2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jessica/opt/anaconda3/envs/IA2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jessica/opt/anaconda3/envs/IA2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jessica/opt/anaconda3/envs/IA2/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/jessica/opt/anaconda3/envs/IA2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jessica/opt/anaconda3/envs/IA2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jessica/opt/anaconda3/envs/IA2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jessica/opt/anaconda3/envs/IA2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jessica/opt/anaconda3/envs/IA2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jessica/opt/anaconda3/envs/IA2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_model_optimization'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a316ae7a70f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_model_optimization\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfmot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_model_optimization'"
     ]
    }
   ],
   "source": [
    "from itertools import repeat\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as pp\n",
    "import pandas as pd\n",
    "from PIL import Image # Importamos la clase Image de la librería **pillow**\n",
    "from matplotlib import image\n",
    "import os\n",
    "from os import listdir\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential #RNA que tiene conexion hacia adelante\n",
    "from keras.layers import Dense, Dropout, Flatten, MaxPooling2D, LeakyReLU #Capas de RNA\n",
    "import keras.optimizers as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de Categorias :::: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bosque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>calle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edificios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>glacial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>montaña</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0     bosque\n",
       "1      calle\n",
       "2  edificios\n",
       "3    glacial\n",
       "4        mar\n",
       "5   montaña"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Cargamos las categorias en orden \n",
    "listaCategorias = os.listdir('./image-dataset-proyecto-integrador-interciclo')\n",
    "listaCategorias.sort(key = str.lower)\n",
    "categorias = pd.DataFrame(listaCategorias)\n",
    "print('Total de Categorias ::::',len(categorias))\n",
    "\n",
    "categorias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerias\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leyendo imagenes de  /Users/jessica/Downloads/image-dataset-proyecto-integrador-interciclo/\n",
      "/Users/jessica/Downloads/image-dataset-proyecto-integrador-interciclo/bosque 1\n",
      "/Users/jessica/Downloads/image-dataset-proyecto-integrador-interciclo/mar 2263\n",
      "/Users/jessica/Downloads/image-dataset-proyecto-integrador-interciclo/edificios 2270\n",
      "/Users/jessica/Downloads/image-dataset-proyecto-integrador-interciclo/calle 2190\n",
      "/Users/jessica/Downloads/image-dataset-proyecto-integrador-interciclo/montaña 2381\n",
      "/Users/jessica/Downloads/image-dataset-proyecto-integrador-interciclo/glacial 2495\n",
      "Directorios leidos: 6\n",
      "Imagenes en cada directorio [2264, 2270, 2190, 2381, 2495, 2386]\n",
      "suma Total de imagenes en subdirs: 13986\n"
     ]
    }
   ],
   "source": [
    "IMG_WIDTH=200\n",
    "IMG_HEIGHT=200\n",
    "batch_size=4\n",
    "img_dir =  r'image-dataset-proyecto-integrador-interciclo'\n",
    "dirname = os.path.join(os.getcwd(), img_dir)\n",
    "imgpath = dirname + os.sep \n",
    " \n",
    "images = []\n",
    "directories = []\n",
    "dircount = []\n",
    "prevRoot=''\n",
    "cant=0\n",
    " \n",
    "print(\"leyendo imagenes de \",imgpath)\n",
    "for root, dirnames, filenames in os.walk(imgpath):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            \n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = plt.imread(filepath)\n",
    "            if len(image) ==150:\n",
    "                cant=cant+1\n",
    "                images.append(image)\n",
    "                b = \"Leyendo...\" + str(cant)\n",
    "                print (b, end=\"\\r\")\n",
    "                if prevRoot !=root:\n",
    "                    print(root, cant)\n",
    "                    prevRoot=root\n",
    "                    directories.append(root)\n",
    "                    dircount.append(cant)\n",
    "                    cant=0\n",
    "dircount.append(cant)\n",
    "dircount = dircount[1:]\n",
    "dircount[0]=dircount[0]+1\n",
    "print('Directorios leidos:',len(directories))\n",
    "print(\"Imagenes en cada directorio\", dircount)\n",
    "print('suma Total de imagenes en subdirs:',sum(dircount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad etiquetas creadas:  13986\n",
      "0 bosque\n",
      "1 mar\n",
      "2 edificios\n",
      "3 calle\n",
      "4 montaña\n",
      "5 glacial\n",
      "Total number of outputs :  6\n",
      "Output classes :  [0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "labels=[]\n",
    "indice=0\n",
    "for cantidad in dircount:\n",
    "    for i in range(cantidad):\n",
    "        labels.append(indice)\n",
    "    indice=indice+1\n",
    "print(\"Cantidad etiquetas creadas: \",len(labels))\n",
    " \n",
    "categorias=[]\n",
    "indice=0\n",
    "for directorio in directories:\n",
    "    name = directorio.split(os.sep)\n",
    "    print(indice , name[len(name)-1])\n",
    "    categorias.append(name[len(name)-1])\n",
    "    indice=indice+1\n",
    "\n",
    "y = np.array(labels)\n",
    "\n",
    "#X = np.array(images, dtype=np.uint8) #convierto de lista a numpy\n",
    "X=np.array(images, dtype=np.uint8)\n",
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(y)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (11188, 150, 150, 3) (11188,)\n",
      "Testing data shape :  (2798, 150, 150, 3) (2798,)\n",
      "Original label: 2\n",
      "After conversion to one-hot: [0. 0. 1. 0. 0. 0.]\n",
      "(8950, 150, 150, 3) (2238, 150, 150, 3) (8950, 6) (2238, 6)\n"
     ]
    }
   ],
   "source": [
    "#Mezclar todo y crear los grupos de entrenamiento y testing\n",
    "train_X,test_X,train_Y,test_Y = train_test_split(X,y,test_size=0.2)\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)\n",
    "\n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255.\n",
    "\n",
    "# Change the labels from categorical to one-hot encoding\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    "\n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', train_Y[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])\n",
    "\n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)\n",
    "\n",
    "print(train_X.shape,valid_X.shape,train_label.shape,valid_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion de la red neuronal tipo secuencial\n",
    "modelo = Sequential()\n",
    "\n",
    "# Nuestra primera capa va a ser una convolucion que va a tener el numero de filtros que definimos, al igual que las dimensiones\n",
    "#de trabajo de las imagenes a procesar y una activacion tipo relu\n",
    "modelo.add(Conv2D(150,(3,3),padding =\"same\",activation='relu',input_shape=(150, 150,3)))\n",
    "#Esta capa aplica un filtro que reduce la dimensionalidad de la imagen, esto es, la hace más pequeña.\n",
    "modelo.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modelo.add(Conv2D(64,(2,2),activation='relu',padding =\"same\"))\n",
    "modelo.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#Aplanar la informacion, una dimension que contiene toda la informacion de nuestra red neuronal\n",
    "modelo.add(Flatten())\n",
    "#Añade una capa que estara conectada a las capas anteriores\n",
    "modelo.add(Dense(256, activation='relu'))\n",
    "# Durante el entrenamiento se apaga cierto numero de nueronas para evitar sobreajustar los datos\n",
    "modelo.add(Dropout(0.5))\n",
    "modelo.add(Dense(100, activation='relu'))\n",
    "modelo.add(Dropout(0.5))\n",
    "# softmas: Valores de porcentaje de probabilidad de determinacion de una categoria\n",
    "modelo.add(Dense(6, activation='softmax'))\n",
    "\n",
    "modelo.summary()\n",
    "#optimizar el procesamiento de los datos, funcion de perdida, para ver q tan bien o mal esta aprendiendo la red neural\n",
    "modelo.compile(loss='categorical_crossentropy',optimizer='nadam',metrics=['accuracy'])\n",
    "#Entrenamiento de la red nueronal\n",
    "historial= modelo.fit(train_X, train_label, \n",
    "                          batch_size=64,epochs=50,\n",
    "                          verbose=1,\n",
    "                          validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA2",
   "language": "python",
   "name": "ia2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
